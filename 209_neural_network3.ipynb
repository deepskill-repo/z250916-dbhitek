{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-V09Yxe9Z1kF"
      },
      "source": [
        "# 신경망 작동법 이해하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lherMp4VGZy"
      },
      "source": [
        "## 신경망의 학습은 어떻게 이루어질까요?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e49EFqbdViZD"
      },
      "source": [
        "아래 이미지를 보면서 신경망이 어떻게 학습을 진행하는지 상상해봅시다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df8QmGkNQdgD"
      },
      "source": [
        "<img src=\"https://i.imgur.com/dlGareT.gif\" alt=\"backpropagation\" width=600>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjZ4HIqeOa9G"
      },
      "source": [
        "- **위 그림에서 설명하고 있는 과정은 다음과 같습니다.**\n",
        "\n",
        "1. 데이터가 입력되면 신경망 각 층에서 **가중치 및 활성화 함수 연산**을 반복적으로 수행합니다.\n",
        "2. 1의 과정을 모든 층에서 반복한 후에 **출력층에서 계산된 값을 출력**합니다.\n",
        "3. **손실 함수**를 사용하여 **예측값(Prediction)과 실제값(Target)의 차이**를 계산합니다.\n",
        "4. **경사하강법과 역전파**를 통해서 **각 가중치를 갱신**합니다.\n",
        "5. 학습 중지 기준을 만족할 때까지 **1-4의 과정을 반복**합니다.\n",
        "\n",
        "1-4의 과정을 **Iteration(이터레이션)**이라고 하며 매 Iteration 마다 가중치가 갱신됩니다.<br/>\n",
        "Iteration 은 **<font color=\"ff6f61\">순전파(1&2), 손실 계산(3), 역전파(4)</font>**로 나눠볼 수 있는데요.<br/>\n",
        "먼저 비유를 통해서 신경망 학습에 대해 알아보고 각 과정에 대해서 하나씩 알아보도록 하겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xlGGjSJRSP"
      },
      "source": [
        "### 순전파(Forward Propagation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNeHKC89vGUX"
      },
      "source": [
        "위에서 알아본 것처럼 신경망은 학습 과정에서 첫 번째로 **<font color=\"ff6f61\">순전파(Forward propagation)</font>**를 수행합니다.<br/>\n",
        "순전파는 **입력층에서 입력된 신호가 은닉층의 연산을 거쳐 출력층에서 값을 내보내는 과정**인데요.\n",
        "\n",
        "위 이미지에서 왼쪽에서 오른쪽으로 신호가 전달되는 과정을 순전파라고 하며<br/>\n",
        "각 층에서의 연산 과정은 다음과 같습니다.\n",
        "\n",
        "1. 입력층(혹은 이전 은닉층)으로부터 신호를 전달받습니다.\n",
        "2. 입력된 데이터에 **가중치-편향 연산**을 수행합니다.\n",
        "3. 가중합을 통해 구해진 값은 **활성화 함수**를 통해 다음 층으로 전달됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTXE6ix3dk51"
      },
      "source": [
        "### 손실 함수(Loss function)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1pPdhnaIjKA"
      },
      "source": [
        "신경망은 손실 함수를 최소화 하는 방향으로 가중치를 갱신합니다.<br/>\n",
        "그렇기 때문에 손실 함수를 잘 정의해주어야 가중치가 제대로 갱신될 수 있겠죠?\n",
        "\n",
        "입력 데이터를 신경망에 넣어 순전파를 거치면 마지막에는 출력층을 통과한 값이 도출됩니다.<br/>\n",
        "이 때 출력된 값과 그 데이터의 타겟값을 **손실 함수에 넣어 손실(Loss or Error)를 계산**하게 됩니다.\n",
        "\n",
        "대표적인 손실 함수로는 여러분이 머신러닝 Section 에서 배웠던<br/>\n",
        "**MSE(Mean-Squared Error), CEE(Cross-Entropy Error)** 등이 있습니다.\n",
        "\n",
        "일반적으로 회귀의 손실 함수로는 **MSE** 혹은 **MAE**를,<br/>\n",
        "이진 분류의 손실 함수로는 **binary_crossentropy**를,<br/>\n",
        "다중 분류의 손실 함수로는 **categorical_crossentropy**와 **sparse_categorical_crossentropy**를 사용합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMi8h8egQrrJ"
      },
      "source": [
        "### 역전파(Backward Propagation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JEOjFrHQaOx"
      },
      "source": [
        "**<font color=\"ff6f61\">역전파(Backpropagation)</font>**는 말 그대로 순전파와는 **반대 방향으로 손실(Loss or Error) 정보를 전달**해주는 과정입니다.\n",
        "\n",
        "순전파가 **입력 신호 정보를 입력층부터 출력층까지 전달하여 값을 출력**하는 알고리즘이었다면,<br/>\n",
        "역전파는 구해진 **손실 정보를 출력층부터 입력층까지 전달하여 각 가중치를 얼마나 업데이트 해야할 지를 구하는** 알고리즘입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8znnSpvAQras"
      },
      "source": [
        "신경망은 매 반복마다 **손실(Loss)을 줄이는 방향**으로 가중치를 업데이트합니다.<br/>\n",
        "그렇다면 **손실을 줄이기 위해서** 어떻게 가중치를 수정해야 할까요?\n",
        "\n",
        "가중치 수정 방향을 결정하는 것이 바로 **<font color=\"ff6f61\">경사 하강법(Gradient Descent, GD)</font>**입니다.<br/>\n",
        "경사 하강법에 대해 알아보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aguCH12CVGZ0"
      },
      "source": [
        "## 경사 하강법(Gradient Descent)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dhx_j25GyaE"
      },
      "source": [
        "아래 그림을 보면 알 수 있듯, **손실 함수 $J$ 의 경사(Gradient)가 작아지는 방향으로 업데이트** 하면 손실 함수의 값을 줄일 수 있습니다.<br/>\n",
        "매 Iteration 마다 **<font color=\"ff6f61\">해당 가중치에서의 비용 함수의 도함수(=비용 함수를 미분한 함수)를 계산</font>하여** 경사가 작아질 수 있도록 가중치를 변경합니다.\n",
        "\n",
        "$i$ 번째 가중치인 $\\theta_i$ 가 갱신되는 모습을 수식으로는 다음과 같이 나타낼 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcjpXc7oU91t"
      },
      "source": [
        "<img src=\"https://i.imgur.com/ic91umJ.png\" height=\"200\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81XORsbhVEOT"
      },
      "source": [
        "그림을 보면서 기울기가 양수(+)일 때에는 왜 왼쪽(-)으로 이동하게 되는지,<br/>\n",
        "기울기가 음수(-)일 때에는 왜 오른쪽(+)으로 이동하게 되는지 생각해봅시다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FV6-h0j5XuAC"
      },
      "source": [
        "<img src=\"https://i.imgur.com/ehYYRtw.png\" height=\"300\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8TDaCMe8YDK"
      },
      "source": [
        "예를 들면, 아래와 같이 가중치가 변하게 됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJV0fh1s8K3v"
      },
      "source": [
        "<img src=\"https://i.imgur.com/ostAP3w.gif\" height=\"300\"/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_nVOZ6amwdZ"
      },
      "source": [
        "### 다시, 역전파"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NC0ZoW62mzvh"
      },
      "source": [
        "그러면 각각의 가중치는 어떻게 갱신될까요?\n",
        "\n",
        "이 과정에서 역전파의 주요 메커니즘인 **편미분**과 **Chain rule(연쇄 법칙)**이 사용됩니다.<br/>\n",
        "위 식에서 볼 수 있었던 것처럼 특정 가중치 $(\\theta_i)$ 에 대한 기울기는\n",
        "아래 식과 같이 손실 함수를 해당 가중치로 **편미분**하여 구할 수 있습니다.\n",
        "\n",
        "$$\n",
        "\\frac{\\partial}{\\partial \\theta_i} J(\\theta)\n",
        "$$\n",
        "\n",
        "<br/>\n",
        "\n",
        "그렇다면 모든 가중치에 대한 값은 어떻게 구할 수 있을까요?<br/>\n",
        "여기서 바로 **Chain rule**이 적용됩니다.<br/>\n",
        "연쇄 법칙이란 아래 식과 같이 특정 변수에 대한 (편)미분 값을 다른 변수의 미분을 사용하여 나타낼 수 있는 방식입니다.\n",
        "\n",
        "$$\n",
        "\\frac{\\partial J(\\theta)}{\\partial \\theta_i} = \\frac{\\partial J(\\theta)}{\\partial \\theta_x} \\cdot \\frac{\\partial \\theta_x}{\\partial \\theta_i} = \\frac{\\partial J(\\theta)}{\\partial \\theta_x} \\cdot \\frac{\\partial \\theta_x}{\\partial \\theta_y} \\cdot \\frac{\\partial \\theta_y}{\\partial \\theta_i}\n",
        "$$\n",
        "\n",
        "<br/>\n",
        "\n",
        "연쇄 법칙을 사용하여 각 변수가 얼마나 수정되어야 할 지에 대한 정보를 전달할 수 있게 됩니다.\n",
        "\n",
        "> ❗️ ***역전파 메커니즘에 대한 수학적인 설명은 Reference를 참조해주세요 !***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obSHWEWzyKUV"
      },
      "source": [
        "### 옵티마이저(Optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEpaTmSiSB8K"
      },
      "source": [
        "다음은 **<font color=\"ff6f61\">옵티마이저(Optimizer)</font>** 입니다.\n",
        "\n",
        "옵티마이저는 쉽게 말해 **<font color=\"ff6f61\">경사를 내려가는 방법을 결정</font>**하는데요.<br/>\n",
        "대표적인 옵티마이저로는 아래와 같은 것들이 있습니다. (다 외우지 않아도 됩니다!)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwgmiQntR_7R"
      },
      "source": [
        "<img src=\"https://i.imgur.com/UQfpjpP.png\" height=\"350\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIIVMCJ4ffD8"
      },
      "source": [
        "일반적인 경사 하강법(GD)에서는 모든 입력 데이터에 대한 손실 함수의 기울기를 계산한 후에 가중치를 업데이트 하였습니다.<br/>\n",
        "즉, Iteration 마다 모든 데이터를 다 사용하게 되는 것이죠.<br/>\n",
        "입력 데이터가 적다면 이 방법으로도 빠르게 가중치를 금방 갱신할 수 있습니다.\n",
        "\n",
        "하지만 실제로는 이보다 훨씬 더 큰 데이터를 다루게 되는데요.<br/>\n",
        "만약 입력 데이터가 수천만개라면 모든 데이터에 대해 손실을 계산하는 과정이 굉장히 오래 걸리게 됩니다.<br/>\n",
        "그러면 가중치를 수정하는데 굉장히 오랜 시간이 들어가겠죠?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zW5oQ-V1R6N-"
      },
      "source": [
        "#### 확률적 경사 하강법(Stochastic Gradient Descent, SGD)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afuCVMEiYj_g"
      },
      "source": [
        "그래서 등장한 것이 바로 **<font color=\"ff6f61\">확률적 경사 하강법</font>**과 **<font color=\"ff6f61\">미니 배치(Mini-batch) 경사 하강법</font>**입니다.\n",
        "\n",
        "확률적 경사 하강법(SGD)은 전체 데이터에서 **하나의 데이터**를 뽑아서 신경망에 입력한 후 손실을 계산합니다.<br/>\n",
        "그리고 그 손실 정보를 역전파하여 신경망의 가중치를 업데이트하게 됩니다.<br/>\n",
        "다시 말하면, Iteration 마다 1개의 데이터만을 사용하는데요.\n",
        "\n",
        "그렇기 때문에 **가중치를 빠르게 업데이트** 할 수 있다는 장점이 있습니다.<br/>\n",
        "물론 확률적 경사 하강법에도 단점이 있습니다. 1개의 데이터만 보기 때문에 학습 과정에서 불안정한 경사 하강을 보인다는 점인데요.\n",
        "\n",
        "아래 그림에서 확률적 경사 하강법(왼쪽)과 일반적인 경사 하강법(오른쪽)에서 경사 하강이 어떻게 일어나는 지의 차이를 볼 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctEjlSZ1Ympr"
      },
      "source": [
        "그래서 두 방법을 적절히 융화한 **미니 배치(Mini-batch) 경사 하강법**이 등장하게 되었습니다.<br/>\n",
        "N개의 데이터로 미니 배치를 구성하여 해당 미니 배치를 신경망에 입력한 후 이 결과를 바탕으로 가중치를 업데이트합니다.<br/>\n",
        "즉, Iteration 마다 N개(=배치 사이즈)의 데이터를 사용하게 됩니다.\n",
        "\n",
        "일반적으로는 두 방법의 장점을 적절히 융화한 미니 배치 경사 하강법을 많이 사용합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiIjO1tuCHCK"
      },
      "source": [
        "- **배치 사이즈(Batch Size)**\n",
        "\n",
        "미니 배치 경사 하강법에서 사용하는 미니 배치의 크기를 **배치 사이즈(Batch size)** 라고 합니다.<br/>\n",
        "일반적으로 배치 사이즈는 2의 배수로 설정하며, 메모리 크기가 허락한다면 큰 배치 사이즈를 쓰는 것이 학습을 안정적으로 진행할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCYNZGruYq88"
      },
      "source": [
        "- **여러 가지 옵티마이저(Optimizer)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krP5bCmNMtWB"
      },
      "source": [
        "<img src=\"https://i.imgur.com/DYoGuTT.gif\" height=\"400\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Xw-3W2kYzrb"
      },
      "source": [
        "여러 가지 옵티마이저 중에서 어떤 것이 가장 좋다고 말하기는 어렵습니다.<br/>\n",
        "문제마다, 데이터마다 달라지기 때문에 여러 옵티마이저를 적용하면서 서로 비교해보아야 하는데요.\n",
        "\n",
        "다음 강의에서 최적의 하이퍼파라미터를 찾아보면서 여러 옵티마이저를 비교해 볼 것입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLgxCdK5v_6e"
      },
      "source": [
        "## Tensorflow 신경망 예제"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziN9Vc4QQCXz"
      },
      "source": [
        "이번 시간에는 또 다른 예제 데이터인 Fashion MNIST 예제를 신경망으로 풀어보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zL3Sog6xktHL"
      },
      "source": [
        "### Fashion MNIST 예제"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJEAiXAz88hM"
      },
      "source": [
        "> ❓ ***그렇다면 MNIST 예제는 이진 분류, 다중 분류, 회귀 중 어디에 속할까요? <br/>\n",
        "<font color=\"ff6f61\">항상 문제를 풀기 전에 자신이 풀고자 하는 문제가 어디에 속하는 지 생각</font>해보도록 합시다.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUjBSQtB9Fo_"
      },
      "source": [
        "1. **먼저 필요한 패키지와 라이브러리를 불러옵니다.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jVtVqIp9JtE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Glc0ohHs9IPw"
      },
      "source": [
        "2. **데이터셋을 불러온 후 학습 데이터셋(Train Dataset)과 시험 데이터셋(Test Dataset)으로 나누어(Split)주고 픽셀값을 정규화 하여줍니다.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ua6p5z159YL9",
        "outputId": "3a7281e1-f27a-400c-d5ff-0b374d59653e"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHuX2beXS929",
        "outputId": "ae41bbe0-5ad5-4683-ac08-232795736103"
      },
      "outputs": [],
      "source": [
        "print(X_train.shape, X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMmF-JWM9msg"
      },
      "source": [
        "이미지 데이터에서는 정규화하는 과정이 중요합니다. 빼먹지 않도록 주의해주세요!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNL0nv5L9jtm"
      },
      "outputs": [],
      "source": [
        "X_train, X_test = X_train / 255.0, X_test / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "AV-FRPkMTMO1",
        "outputId": "5d8251e2-07a2-4a36-92e3-e97d50468f8f"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for i in range(9):\n",
        "    plt.subplot(3, 3, i+1)\n",
        "\n",
        "    plt.imshow(X_train[i], cmap=plt.get_cmap('gray'))\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzJ9Wejf9Xst"
      },
      "source": [
        "3. **레이블이 어떻게 구성되어 있는 지 확인해봅니다.**\n",
        "\n",
        "    데이터의 레이블 구성 형태를 살펴봅니다.<br/>\n",
        "    처음보는 데이터의 경우 데이터 자체를 디스플레이 하여 보면 도움이 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOKNf_559eye",
        "outputId": "8bef3d7f-b3eb-4989-ac44-93b48e8a9093"
      },
      "outputs": [],
      "source": [
        "np.unique(y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCCLTvqu98bE"
      },
      "source": [
        "4. **이제 본격적으로 신경망 모델을 구축해보겠습니다.**\n",
        "\n",
        "> ❗️ ***아래 코드에서 출력층의 노드 수는 몇 개인지, 출력층의 활성화 함수는 무엇인지, 손실 함수는 어떻게 지정하였는지에 주목해봅시다.***<br/>\n",
        "❗️ ***`.summary()`를 활용하면 모델의 구조를 빠르게 파악해 볼 수 있습니다.***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0LVdBzF98J3"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(28, 28)))\n",
        "model.add(Dense(10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ysFo2tw0TakE"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ce49C91l-TuM",
        "outputId": "a5c4fa1c-c103-4a33-fed4-f5f2cfd604da"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXkvdWo-T23F"
      },
      "source": [
        "> ❗️ ***위 모델의 파라미터 수는 총 7,850개입니다. 왜 7,850개가 될 지에 대해 생각해봅시다.***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_J92keOlIDf",
        "outputId": "ca1adfce-3551-4764-e449-b7040120784b"
      },
      "outputs": [],
      "source": [
        "model.fit(X_train, y_train, epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knPbosgK-xtc"
      },
      "source": [
        "5. **학습한 신경망 모델을 사용하여 평가합니다.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90hFOU1XBA82",
        "outputId": "de4f128e-07e0-41fa-bd99-010e9a6becae"
      },
      "outputs": [],
      "source": [
        "model.evaluate(X_test,  y_test, verbose=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqd1TOUv6102"
      },
      "source": [
        "### 추가 고려 사항\n",
        "\n",
        "- **학습률(Learning rate)**\n",
        "\n",
        "    **<font color=\"ff6f61\">학습률(Learning rate, `lr`)</font>**이란 매 가중치에 대해 구해진 기울기 값을 얼마나 경사 하강법에 적용할 지를 결정하는 하이퍼파라미터입니다.  \n",
        "    지난 시간에 보았던 경사 하강법 수식에서 학습률이 어디에 위치하는지 확인해봅시다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AVX33ZINayy"
      },
      "source": [
        "<img src=\"https://i.imgur.com/ic91umJ.png\" height=\"200\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCZyAvXYNeBl"
      },
      "source": [
        "위 식에서 볼 수 있는 것처럼 해당 지점에서의 기울기를 구하여 기울기가 감소하는$(-)$ 방향으로 이동하게 되는데요.<br/>\n",
        "학습률은 **얼마나 이동할 지를 조정하는 하이퍼파라미터**입니다.\n",
        "\n",
        "경사 하강법이 산길을 내려가는 과정이라면 학습률은 **보폭을 결정**하게 됩니다.<br/>\n",
        "학습률이 크면 보폭이 크니 Iteration 마다 성큼성큼 이동하고, 작으면 보폭이 작아 조금씩만 이동하게 됩니다.<br/>\n",
        "그렇다면 학습률을 잘못 설정하면 어떻게 될까요?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbBjzju8N1zo"
      },
      "source": [
        "- **학습률이 너무 크거나 작으면 어떻게 될까요?**\n",
        "\n",
        "> ❗️ *아래는 학습률이 너무 클 때와 작을 때의 경사하강법을 나타낸 그림입니다.*  \n",
        "> *그림을 기억하면서 최적의 학습률이 왜 중요한 지에 대해 생각해봅시다.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JJV693y7fUC"
      },
      "source": [
        "<img src=\"https://i.imgur.com/RfBFgKs.png\" height=\"300\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-hKd9jMK6xE"
      },
      "source": [
        "그림에서 확인할 수 있는 것처럼<br/>\n",
        "**학습률이 너무 낮으면 최적점에 이르기까지 너무 오래 걸리거나, 주어진 Iteration 내에서 최적점에 도달하는 데 실패**하기도 합니다.<br/>\n",
        "반대로 **너무 높으면 경사 하강 과정에서 발산하면서 모델이 최적값을 찾을 수 없게** 되어버립니다.\n",
        "\n",
        "그렇기 때문에 최적의 학습률을 찾는 것은 학습에서 중요한 요소인데요.<br/>\n",
        "위와 같은 문제를 해결하기 위해서 사용되는 방법이 **학습률 감소/계획법**입니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONqTmzH6cBTo"
      },
      "source": [
        "**학습률 감소(Learning rate Decay)**\n",
        "\n",
        "학습률 감소는 Adagrad, RMSprop, Adam 과 같은 주요 옵티마이저에 이미 구현되어 있기 때문에 쉽게 적용할 수 있습니다.  \n",
        "해당 옵티마티저의 하이퍼파라미터를 조정하면 감소 정도를 변화시킬 수 있습니다.\n",
        "\n",
        "아래와 같이 **`.compile`** 내에 있는 **`optimizer=`** 에 Adam 등의 옵티마이저 적용 후 내부 하이퍼파라미터를 변경하면 학습률 감소를 적용할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjwyqm0xAwAA",
        "outputId": "48579d49-fc47-4d4f-b042-8bde9c2aaedc"
      },
      "outputs": [],
      "source": [
        "# optimizer 내 lr(learning rate) 인자를 통해 학습률을 설정할 수 있습니다. beta_1 인자는 학습률 감소율을 설정하며 Adam 내 수식의 변수를 그대로 사용합니다.\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, beta_1 = 0.89), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SQsF4emxP1-"
      },
      "source": [
        " * Dropout (드롭아웃)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWndbcDy20UL"
      },
      "source": [
        "**Dropout(드롭아웃)**은 Iteration 마다 **레이어 노드 중 일부를 사용하지 않으면서 학습을 진행하는 방법**입니다.<br/>\n",
        "매 번 다른 노드가 학습되면서 전체 가중치가 과적합되는 것을 방지할 수 있습니다.<br/>\n",
        "아래는 Dropout을 적용했을 때의 신경망에서 학습되는 노드를 나타낸 그림입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5M7ArjZG-lZ"
      },
      "source": [
        "<img src=\"https://i.imgur.com/rAyIZxV.png\" height=\"300\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnxtUB2kHHqO"
      },
      "source": [
        "Dropout 을 적용할 때에는 0~1 사이의 실수를 입력하게 되는데요.<br/>\n",
        "모델 내에 있는 특정 레이어의 노드 연결을 지정해 준 비율만큼 강제로 끊습니다.<br/>\n",
        "매 Iteration 마다 랜덤하게 노드를 차단하여 다른 가중치를 학습하도록 조정하기 때문에 과적합을 방지할 수 있게 됩니다.\n",
        "\n",
        "Keras 에서는 아래와 같이 Dropout 을 적용하고 싶은 층 다음에 `Dropout` 함수를 추가하면 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IoloPCLn-aN3"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "Dense(64,\n",
        "      kernel_regularizer=regularizers.l2(0.01),\n",
        "      activity_regularizer=regularizers.l1(0.01))\n",
        "Dropout(0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeq9Fkhm3BlY"
      },
      "source": [
        "### Fashion MNIST 신경망 예제에 기법 적용하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pf415x9HeuHJ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-shEO-j7YVC"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuHlAVpS4ix1"
      },
      "source": [
        "1) **데이터셋을 불러옵니다.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXzVrPl3jZSL",
        "outputId": "0e29b28a-26f3-4513-f8a7-47b5c149ccef"
      },
      "outputs": [],
      "source": [
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "print(X_train.shape, X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8ETLEjs4k5w"
      },
      "source": [
        "2) **데이터를 정규화(Normalization)합니다.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGkSj-XVjdOP"
      },
      "outputs": [],
      "source": [
        "X_train = X_train / 255\n",
        "X_test = X_test / 255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TORaDD1U4uMI"
      },
      "source": [
        "3) **레이블의 개수와 형태를 확인합니다.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GF-QSeSLjdp0",
        "outputId": "6763f543-b1b3-465f-e605-087bfea0eea3"
      },
      "outputs": [],
      "source": [
        "np.unique(y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCC0Z2ZH49ih"
      },
      "source": [
        "4) **신경망 모델을 구축하고 Compile 합니다.**\n",
        "\n",
        "  구축 과정에서 위에서 학습하였던 **Weight Decay(가중치 감소), Dropout(드롭아웃)**을 적용해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZBg5E4ZjSrQ"
      },
      "outputs": [],
      "source": [
        "# 기본적인 신경망을 만드는 코드\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(64,\n",
        "          kernel_regularizer=regularizers.l2(0.01),\n",
        "          activity_regularizer=regularizers.l1(0.01)),\n",
        "    Dropout(0.5),\n",
        "    Dense(10, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzSIlxcx5SBG"
      },
      "source": [
        "Compile 설정에서 위에서 학습하였던 **Learning rate Decay(학습률 감소)**를 적용해봅니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TkJM3eSR3ue9"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, beta_1 = 0.89)\n",
        "             , loss='sparse_categorical_crossentropy'\n",
        "             , metrics=[tf.keras.metrics.Precision()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFqWpUI1jmrS",
        "outputId": "f6a1ab6b-fe6d-4ffe-a607-4cb81a8b77f3"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpno3z7S5ba1"
      },
      "source": [
        "5) **신경망 모델을 학습합니다.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puMqk6o8AVjn",
        "outputId": "da87de69-cce9-400b-d6ae-39fe7f7dcf86"
      },
      "outputs": [],
      "source": [
        "model.fit(X_train, y_train, batch_size=32, epochs=30, verbose=1,\n",
        "          validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMFmcflC03L7"
      },
      "source": [
        "6) **모델을 사용하여 평가를 진행합니다.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTfCeDeOlDt9",
        "outputId": "24280837-cb90-4229-ed95-f27113688246"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=2)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
